# ğŸ«€ Heart Failure Prediction Analysis

## ğŸ“Œ DescripciÃ³n del Proyecto

Este proyecto tiene como objetivo predecir la **probabilidad de fallo cardÃ­aco** utilizando un conjunto de datos pÃºblico disponible en **Kaggle**. El anÃ¡lisis incluye la carga de datos, exploraciÃ³n, preprocesamiento y la implementaciÃ³n de modelos de aprendizaje automÃ¡tico para predecir la presencia de enfermedades cardÃ­acas.

---

## ğŸ“Š Dataset

El conjunto de datos utilizado es **"Heart Failure Prediction"** de Kaggle, que contiene **918 registros** y **12 caracterÃ­sticas** relacionadas con la salud cardiovascular:

- `Age` â€” Edad  
- `Sex` â€” Sexo  
- `ChestPainType` â€” Tipo de dolor en el pecho  
- `RestingBP` â€” PresiÃ³n arterial en reposo  
- `Cholesterol` â€” Colesterol  
- `FastingBS` â€” AzÃºcar en sangre en ayunas  
- `RestingECG` â€” Electrocardiograma en reposo  
- `MaxHR` â€” Frecuencia cardÃ­aca mÃ¡xima  
- `ExerciseAngina` â€” Angina inducida por ejercicio  
- `Oldpeak` â€” DepresiÃ³n del segmento ST  
- `ST_Slope` â€” Pendiente del segmento ST  
- `HeartDisease` â€” **Variable objetivo** (0 = No, 1 = SÃ­)  

---

## ğŸ—‚ï¸ Estructura del Proyecto

El proyecto estÃ¡ organizado en el archivo `Prediccion_Cora.ipynb`, que incluye las siguientes secciones:

1. **Carga de Paquetes**  
   ImportaciÃ³n de bibliotecas como `pandas`, `numpy`, `matplotlib`, `seaborn`, `scikit-learn`, `catboost` y `xgboost`.

2. **Carga de Datos**  
   Descarga desde Kaggle y carga en un `DataFrame`.

3. **AnÃ¡lisis Exploratorio (EDA)**  
   - InformaciÃ³n general del dataset  
   - EstadÃ­sticas descriptivas  
   - DetecciÃ³n de valores faltantes  
   - VisualizaciÃ³n de distribuciones y correlaciones

4. **Preprocesamiento**  
   - DivisiÃ³n en conjunto de entrenamiento y prueba  
   - Escalado de caracterÃ­sticas

5. **Modelado**  
   - ImplementaciÃ³n de modelos como `RandomForestClassifier`, `CatBoostClassifier` y `XGBClassifier`  
   - OptimizaciÃ³n de hiperparÃ¡metros con `GridSearchCV`  
   - EvaluaciÃ³n con mÃ©tricas como **Accuracy**, **AUC-ROC**, y **F1-score**

6. **Resultados**  
   - ComparaciÃ³n de rendimiento  
   - SelecciÃ³n del mejor modelo

---

## ğŸ› ï¸ Requisitos

Instala las bibliotecas necesarias:

```bash
pip install pandas numpy matplotlib seaborn scikit-learn catboost xgboost kagglehub
```

## ğŸ‘¤ Autor
Pedro David Yacila AramburÃº
Estudiante de IngenierÃ­a EstadÃ­stica e InformÃ¡tica
Apasionado por el anÃ¡lisis de datos, machine learning 

## ğŸ“« Contacto
GitHub: YacilaPedro

LinkedIn: https://www.linkedin.com/in/pedro-david-yacila-5a2868264/
